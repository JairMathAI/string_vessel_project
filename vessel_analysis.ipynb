{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vessel_analysis_3d.processing_pipeline import Pipeline3D\n",
    "from skimage.morphology import skeletonize\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from aicsimageio import AICSImage\n",
    "from skimage.morphology import label, remove_small_objects, remove_small_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vessel_analysis_3d.graph.networkx_from_array import get_networkx_graph_from_array\n",
    "from vessel_analysis_3d.graph.core import GraphObj\n",
    "from vessel_analysis_3d.graph.stats_reporting import report_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure setting the pixel Dimension properly. For other parameters, please refer\n",
    "# https://www.cell.com/cell-reports-methods/pdf/S2667-2375(23)00051-6.pdf\n",
    "# see Table 1 on page 4.\n",
    "params = {\n",
    "    \"pixelDimensions\": [1.0, 1.0, 1.0],\n",
    "    \"pruningScale\": 1,\n",
    "    \"lengthLimit\": 1,\n",
    "    \"diaScale\": 1,\n",
    "    \"branchingThreshold\": 0.25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = Path(\"/path/to/segmentation/results\")\n",
    "filenames = sorted(pred_path.glob(\"*.tiff\"))\n",
    "\n",
    "# in this analysis, we will generate one or two \"raw\" statistics for each file (if valid string\n",
    "# vessels are detected, then there will be two statistics: one for all vessels and one for only\n",
    "# string vessels. If no valid string vessels are detected, then only one statistics for all \n",
    "# vessels), and also a summary csv. Here, we specify the path to save the \"raw\" statistics \n",
    "# and the filename of the summary file\n",
    "out_path = Path(\"/path/to/save/all/stats\")\n",
    "save_name = out_path / Path(\"data_full_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = AICSImage(filenames[0]).get_image_data(\"ZYX\", C=0, T=0)\n",
    "string_vessel = pred == 2\n",
    "all_vessel = pred > 0\n",
    "\n",
    "string_skl = skeletonize(string_vessel > 0, method=\"lee\").astype(np.uint8)\n",
    "string_skl[string_skl > 0] = 1\n",
    "\n",
    "skl_final, brPts, endPts, reports = Pipeline3D.process_one_file(string_vessel, string_skl, params)\n",
    "\n",
    "stats = []\n",
    "num = 0\n",
    "for fn in filenames:\n",
    "    num = num + 1\n",
    "    print(\"--Analyzing the result: \", num,'/',len(filenames), \"...\")\n",
    "\n",
    "    fileID = fn.stem\n",
    "    pred = AICSImage(fn).get_image_data(\"ZYX\", C=0, T=0)\n",
    "\n",
    "    # here, in this demo, we run analysis on string vessel only and on all vessels\n",
    "    # we can also run on normal vessel only (pred == 1)\n",
    "    string_vessel = pred == 2\n",
    "    all_vessel = pred > 0\n",
    "\n",
    "    _, num_string = label(string_vessel, connectivity=3, return_num=True)\n",
    "\n",
    "    all_skl = skeletonize(all_vessel > 0, method=\"lee\").astype(np.uint8)\n",
    "    all_skl[all_skl > 0] = 1\n",
    "    _, _, _, all_reports = Pipeline3D.process_one_file(all_vessel, all_skl, params)\n",
    "\n",
    "    raw_stats_name = f\"{fileID}_all_vessels_stats.csv\"\n",
    "    all_reports[0].to_csv(raw_stats_name, index=False)\n",
    "\n",
    "    if num_string > 0:\n",
    "\n",
    "        string_skl = skeletonize(string_vessel > 0, method=\"lee\").astype(np.uint8)\n",
    "        string_skl[string_skl > 0] = 1\n",
    "\n",
    "        # skeleton to graph\n",
    "        networkxGraph = get_networkx_graph_from_array(string_skl)\n",
    "\n",
    "        # Statistical Analysis\n",
    "        gh = GraphObj(string_vessel, string_skl, networkxGraph, **params)\n",
    "        skl_final = gh.prune_and_analyze(return_final_skel=True)\n",
    "\n",
    "        if np.count_nonzero(skl_final) < 3:\n",
    "            stats.append(\n",
    "                {\n",
    "                    \"filename\": fileID,\n",
    "                    \"num_string_vessel\": 0,\n",
    "                    \"average_thickness_string\": 0,\n",
    "                    \"average_straightness_string\": 0,\n",
    "                    \"average_length_string\": 0,\n",
    "                    \"string_to_all_ratio\": 0,\n",
    "                    \"average_thickness_all\": np.mean(all_reports[0][\"diameter\"]),\n",
    "                    \"average_straightness_all\": np.mean(all_reports[0][\"straightness\"]),\n",
    "                    \"average_length_all\": np.mean(all_reports[0][\"length\"]),\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            string_reports = report_everything(gh, \"default\")\n",
    "            # save the string report\n",
    "            raw_string_stats_name = f\"{fileID}_string_vessels_stats.csv\"\n",
    "            string_reports[0].to_csv(raw_string_stats_name, index=False)\n",
    "            stats.append(\n",
    "                {\n",
    "                    \"filename\": fileID,\n",
    "                    \"num_string_vessel\": num_string,\n",
    "                    \"average_thickness_string\": np.mean(string_reports[0][\"diameter\"]),\n",
    "                    \"average_straightness_string\": np.mean(string_reports[0][\"straightness\"]),\n",
    "                    \"average_length_string\": np.mean(string_reports[0][\"length\"]),\n",
    "                    \"string_to_all_ratio\": len(string_reports[0]) / len(all_reports[0]),\n",
    "                    \"average_thickness_all\": np.mean(all_reports[0][\"diameter\"]),\n",
    "                    \"average_straightness_all\": np.mean(all_reports[0][\"straightness\"]),\n",
    "                    \"average_length_all\": np.mean(all_reports[0][\"length\"]),\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        stats.append(\n",
    "            {\n",
    "                \"filename\": fileID,\n",
    "                \"num_string_vessel\": 0,\n",
    "                \"average_thickness_string\": 0,\n",
    "                \"average_straightness_string\": 0,\n",
    "                \"average_length_string\": 0,\n",
    "                \"string_to_all_ratio\": 0,\n",
    "                \"average_thickness_all\": np.mean(all_reports[0][\"diameter\"]),\n",
    "                \"average_straightness_all\": np.mean(all_reports[0][\"straightness\"]),\n",
    "                \"average_length_all\": np.mean(all_reports[0][\"length\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "# save_name = \"Data_1_full_stats.csv\"\n",
    "stats_df.to_csv(save_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc_workbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0a6b497edbe280d9c9c3fe7b26d28e91277df791e6ef10dec6644aa4f1f4e76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
